{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CoNLL-U parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "def parser(file):\n",
    "    # file should be .conllu\n",
    "    data_file = open(file, \"r\", encoding=\"utf-8\")\n",
    "    res_file = \"\"\n",
    "    for j in data_file:\n",
    "        res_file+=j\n",
    "    res = res_file.split('\\n')\n",
    "    for i in range(len(res)):\n",
    "        res[i] = res[i].split()\n",
    "    res_list = []\n",
    "    i_list = 0\n",
    "    for line in res:\n",
    "        if not line:\n",
    "            i_list+=1\n",
    "            continue\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        if line[0] == '1':\n",
    "            res_list.append([(line[1],line[3])])\n",
    "            continue\n",
    "        if 48 < ord(line[0][0]) < 58 and '-' not in line[0]:\n",
    "            # here this condition is used to fix the issue when we have a number with space, ex: 48 230\n",
    "            if 47 < ord(line[1][0]) < 58 and 47 < ord(line[2][0]) < 58 and 47 < ord(line[3][0]) < 58:\n",
    "                res_list[i_list].append((line[1],\"NUM\"))\n",
    "                continue\n",
    "            res_list[i_list].append((line[1],line[3]))\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_french_train = parser(\"UD_French-GSD/fr_gsd-ud-train.conllu\")\n",
    "res_french_test = parser(\"UD_French-GSD/fr_gsd-ud-test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_french = [[word] for wt in res_french_train for word,tag in wt]\n",
    "Y_train_french = [[tag] for wt in res_french_train for word,tag in wt]\n",
    "\n",
    "X_test_french = [[word] for wt in res_french_test for word,tag in wt]\n",
    "Y_test_french = [[tag] for wt in res_french_test for word,tag in wt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fr = np.array(X_train_french)\n",
    "Y_train_fr= np.array(Y_train_french)\n",
    "\n",
    "X_test_fr = np.array(X_test_french)\n",
    "Y_test_fr= np.array(Y_test_french)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we start with the length of the word as basic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_np = np.vectorize(len)\n",
    "X_train = len_np(X_train_fr)\n",
    "\n",
    "X_test = len_np(X_test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train,Y_train_fr)\n",
    "res_pred = pp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02486518873576992"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_length = nb/i\n",
    "res_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we use feature based on gramatical rule of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_feature_french_language(word):\n",
    "    tag = \"NOUN\"\n",
    "    if word.endswith(\"s\"):\n",
    "        tag = \"NOUN\"\n",
    "    elif word.endswith(\"ment\"):\n",
    "        tag = \"ADV\"\n",
    "    elif word.endswith(\"er\"):\n",
    "        tag = \"VERB\"\n",
    "    elif word.endswith(\"e\"):\n",
    "        tag = \"NOUN\"\n",
    "    if word.startswith(\"dé\"):\n",
    "        tag = \"VERB\"\n",
    "    elif word.startswith(\"pré\"):\n",
    "        tag = \"NOUN\"\n",
    "    elif word.startswith(\"sous\"):\n",
    "        tag = \"ADP\"\n",
    "    if word.endswith(\"ion\"):\n",
    "        tag = \"NOUN\"\n",
    "    elif word.endswith(\"ier\"):\n",
    "        tag = \"NOUN\"\n",
    "    elif word.endswith(\"ité\"):\n",
    "        tag = \"NOUN\"\n",
    "    if word == \"est\":\n",
    "        tag = \"VERB\"\n",
    "    elif word == \"et\":\n",
    "        tag = \"CCONJ\"\n",
    "    elif word == \"de\":\n",
    "        tag = \"ADP\"\n",
    "    elif 47 < ord(word[0]) < 58:\n",
    "        tag = \"NUM\"\n",
    "    return tag\n",
    "\n",
    "def length_word_feature(word):\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_fr.shape\n",
    "res_y = {}\n",
    "num_y = {}\n",
    "num = 0\n",
    "for i in range(len(Y_train_fr)):\n",
    "    if Y_train_fr[i][0] not in res_y:\n",
    "        res_y[Y_train_fr[i][0]] = 1\n",
    "        num_y[Y_train_fr[i][0]] = num\n",
    "        num+=1\n",
    "    else:\n",
    "        res_y[Y_train_fr[i][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_wd = np.vectorize(simple_feature_french_language)\n",
    "X_train = feat_wd(X_train_fr)\n",
    "X_test = feat_wd(X_test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = np.arange(16)\n",
    "y_hot_coding = np.zeros((y_c.size, y_c.max()+1))\n",
    "y_hot_coding[np.arange(y_c.size), y_c] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vect(X_TR):\n",
    "    res = []\n",
    "    for x in X_TR:\n",
    "        nb = num_y[x[0]]\n",
    "        res.append(y_hot_coding[nb])\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb = to_vect(X_train)\n",
    "X_test_nb = to_vect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train_nb,Y_train_fr)\n",
    "res_pred = pp.predict(X_test_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15688036748552028"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i][0] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_gram = nb/i\n",
    "res_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we combine the 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_np = np.vectorize(len)\n",
    "X_train_f = len_np(X_train_fr)\n",
    "\n",
    "X_test_f = len_np(X_test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat = np.concatenate((X_train_nb, X_train_f), axis=1)\n",
    "X_test_concat = np.concatenate((X_test_nb, X_test_f), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train_concat,Y_train_fr)\n",
    "res_pred = pp.predict(X_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18094667465548234"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i][0] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_concat = nb/i\n",
    "res_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we use the pca matrix to reduce the dimension of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit(X_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.fit_transform(X_test_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train_pca,Y_train_fr)\n",
    "res_pred = pp.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33992410625124825"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i][0] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_pca = nb/i\n",
    "res_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we add to the pca matrix a feature of a rule using the left and the right neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_neigb = []\n",
    "for sentence in res_french_train:\n",
    "    for i, (word,tag) in enumerate(sentence):\n",
    "        if i == 0:\n",
    "            res_neigb.append([(word,tag),(word,tag),sentence[i+1]])\n",
    "        elif i == len(sentence)-1:\n",
    "            res_neigb.append([sentence[i-1],(word,tag),(word,tag)])\n",
    "        else:\n",
    "            res_neigb.append([sentence[i-1],(word,tag),sentence[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neigb = []\n",
    "for sentence in res_french_test:\n",
    "    for i, (word,tag) in enumerate(sentence):\n",
    "        if i == 0:\n",
    "            test_neigb.append([(word,tag),(word,tag),sentence[i+1]])\n",
    "        elif i == len(sentence)-1:\n",
    "            test_neigb.append([sentence[i-1],(word,tag),(word,tag)])\n",
    "        else:\n",
    "            test_neigb.append([sentence[i-1],(word,tag),sentence[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbor_feature(word_list):\n",
    "    tag = \"NOUN\"\n",
    "    word = word_list[1][0]\n",
    "    left_word = word_list[0][0]\n",
    "    right_word = word_list[2][0]\n",
    "    right_tag = word_list[2][1]\n",
    "    left_tag = word_list[0][1]\n",
    "    \n",
    "    if left_word == word and right_tag in ['ADJ', 'NOUN']:\n",
    "        tag = 'DET'\n",
    "    if left_tag == \"DET\" and right_tag == \"ADJ\":\n",
    "        tag = \"NOUN\"\n",
    "    elif left_tag == \"DET\" and right_tag == \"VERB\":\n",
    "        tag = \"NOUN\"\n",
    "    elif left_tag == \"DET\" and right_tag == \"NOUN\":\n",
    "        tag = \"ADJ\"\n",
    "    elif left_tag == \"DET\":\n",
    "        tag = \"NOUN\"\n",
    "    elif word.endswith(\"ment\") and right_word in [\"de\", \"à\"]:\n",
    "        tag = \"ADV\"\n",
    "    elif right_word == \"NOUN\":\n",
    "        tag = \"DET\"\n",
    "    elif 47 < ord(left_word[0]) < 58:\n",
    "        tag = \"NOUN\"\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_neib = []\n",
    "for seq in res_neigb:\n",
    "    x_neib.append(neighbor_feature(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_neib_t = []\n",
    "for seq in test_neigb:\n",
    "    x_neib_t.append(neighbor_feature(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tri = np.array(x_neib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tri = np.array(x_neib_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nb_tri = []\n",
    "for j in X_train_tri:\n",
    "    nb = num_y[j]\n",
    "    X_train_nb_tri.append(y_hot_coding[nb])\n",
    "X_train_nb_tri = np.array(X_train_nb_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nb_tri = []\n",
    "for j in X_test_tri:\n",
    "    nb = num_y[j]\n",
    "    X_test_nb_tri.append(y_hot_coding[nb])\n",
    "X_test_nb_tri = np.array(X_test_nb_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train_nb_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_nb = pca.fit_transform(X_train_nb_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_nb = pca.fit_transform(X_test_nb_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat_nb = np.concatenate((X_train_pca, X_train_pca_nb), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_concat_nb = np.concatenate((X_test_pca, X_test_pca_nb), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train_concat_nb,Y_train_fr)\n",
    "res_pred = pp.predict(X_test_concat_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20311563810665068"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i][0] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_pca_rule_neighbor = nb/i\n",
    "res_pca_rule_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we add to the pca matrix, the feature of the left and right neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_left = []\n",
    "for h in range(len(res_neigb)):\n",
    "    neig_left.append(res_neigb[h][0][0])\n",
    "\n",
    "\n",
    "neig_right = []\n",
    "for h in range(len(res_neigb)):\n",
    "    neig_right.append(res_neigb[h][2][0])\n",
    "\n",
    "\n",
    "neig_left_test = []\n",
    "for h in range(len(test_neigb)):\n",
    "    neig_left_test.append(test_neigb[h][0][0])\n",
    "\n",
    "\n",
    "neig_right_test = []\n",
    "for h in range(len(test_neigb)):\n",
    "    neig_right_test.append(test_neigb[h][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_left = feat_wd(neig_left)\n",
    "X_test_left = feat_wd(neig_left_test)\n",
    "\n",
    "X_train_right = feat_wd(neig_right)\n",
    "X_test_right = feat_wd(neig_right_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_vt(xt):\n",
    "    res = []\n",
    "    for x in xt:\n",
    "        nb = num_y[x]\n",
    "        res.append(y_hot_coding[nb])\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_right = nb_vt(X_train_right)\n",
    "X_test_right = nb_vt(X_test_right)\n",
    "\n",
    "X_train_left = nb_vt(X_train_left)\n",
    "X_test_left = nb_vt(X_test_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train_right)\n",
    "\n",
    "X_train_right = pca.fit_transform(X_train_right)\n",
    "X_train_left = pca.fit_transform(X_train_left)\n",
    "\n",
    "X_test_right = pca.fit_transform(X_test_right)\n",
    "X_test_left = pca.fit_transform(X_test_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat_rt = np.concatenate((X_train_pca, X_train_right), axis=1)\n",
    "X_train_concat_rt = np.concatenate((X_train_concat_rt, X_train_left), axis=1)\n",
    "\n",
    "X_test_concat_rt = np.concatenate((X_test_pca, X_test_right), axis=1)\n",
    "X_test_concat_rt = np.concatenate((X_test_concat_rt, X_test_left), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "pp = Perceptron().fit(X_train_concat_rt,Y_train_fr)\n",
    "res_pred = pp.predict(X_test_concat_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2353704813261434"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 0\n",
    "for i in range(len(res_pred)):\n",
    "    if Y_test_fr[i][0] == res_pred[i]:\n",
    "        nb+=1\n",
    "res_fin_pca_left_right = nb/i\n",
    "res_fin_pca_left_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in this notebook, we only work on the French table, since we are late on the project and so we wanted to test the different possible combinations for the features, since to test the English one's, we have to add new grammar rules, but no time remain for us, and we are already late.\n",
    "So we tried to write some grammar rules to create the features for the french table.\n",
    "Here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using only the length feature: 2.5%\n",
      "Accuracy using only the grammatical rules feature: 15.7%\n",
      "Accuracy using the combination between the length and grammatical features: 18.0%\n",
      "Accuracy using pca on the concatenation: 34.0%\n",
      "Accuracy using the combination between the pca and the grammatical rules on the neighbor: 20.3%\n",
      "Accuracy using the combination between the pca and the grammatical feature of the left and right neighbors: 23.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy using only the length feature: {round(res_length,3)*100}%\") \n",
    "print(f\"Accuracy using only the grammatical rules feature: {round(res_gram,3)*100}%\") \n",
    "print(f\"Accuracy using the combination between the length and grammatical features: {round(res_concat,2)*100}%\") \n",
    "print(f\"Accuracy using pca on the concatenation: {round(res_pca,3)*100}%\")\n",
    "print(f\"Accuracy using the combination between the pca and the grammatical rules on the neighbor: {round(res_pca_rule_neighbor,3)*100}%\") \n",
    "print(f\"Accuracy using the combination between the pca and the grammatical feature of the left and right neighbors: {round(res_fin_pca_left_right,3)*100}%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value obtained is that of the pca after concatenation of the two simple features, and we can see that by using\n",
    "grammatical rules the result is better than a naive method like the length of the word.\n",
    "But what is not expected is that the accuracy will decrease when adding grammatical rules using neighbors,\n",
    "or when just adding the features of the neighbors.\n",
    "However, in our case this is understandable since our grammatical function is not relevant enough.\n",
    "If we have more time we'll concentrate more on the part of creating grammatical rules for both words and neighbors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
