{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa470b7c",
   "metadata": {},
   "source": [
    "# Dimension reduction in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0978433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:23:57.304453Z",
     "start_time": "2021-10-05T06:23:56.618718Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a771959f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T16:31:28.778159Z",
     "start_time": "2021-10-04T16:31:28.770061Z"
    }
   },
   "source": [
    "## the lab\n",
    "\n",
    "You can choose one of the following data sets:\n",
    "- **MNIST:** The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
    "- **Fashion MNIST:** Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples.\n",
    "- **CIFAR10:** The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The following cells allow you to load each of the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65fcb48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:31:46.050366Z",
     "start_time": "2021-10-05T06:31:45.599003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# In the rest of this exercise, use only the test part of Fashion MINIST which already includes 10.000 images.\n",
    "data = X_test\n",
    "target = y_test\n",
    "\n",
    "# For a better understanding, let's create a dictionary that will have class names\n",
    "# with their corresponding categorical class labels.\n",
    "label_dict = {\n",
    " 0: '0',\n",
    " 1: '1',\n",
    " 2: '2',\n",
    " 3: '3',\n",
    " 4: '4',\n",
    " 5: '5',\n",
    " 6: '6',\n",
    " 7: '7',\n",
    " 8: '8',\n",
    " 9: '8',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2c9023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:33:25.966561Z",
     "start_time": "2021-10-05T06:33:25.576978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion MINIST dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "# In the rest of this exercise, use only the test part of Fashion MINIST which already includes 10.000 images.\n",
    "data = X_test\n",
    "target = y_test\n",
    "\n",
    "# For a better understanding, let's create a dictionary that will have class names\n",
    "# with their corresponding categorical class labels.\n",
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f345ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:33:27.499893Z",
     "start_time": "2021-10-05T06:33:26.467525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 26s 0us/step\n",
      "170508288/170498071 [==============================] - 26s 0us/step\n",
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# In the rest of this exercise, use only the test part of CIFAR which already includes 10.000 images.\n",
    "data = X_test\n",
    "target = y_test\n",
    "\n",
    "# For a better understanding, let's create a dictionary that will have class names\n",
    "# with their corresponding categorical class labels.\n",
    "label_dict = {\n",
    " 0: 'airplane',\n",
    " 1: 'automobile',\n",
    " 2: 'bird',\n",
    " 3: 'cat',\n",
    " 4: 'deer',\n",
    " 5: 'dog',\n",
    " 6: 'frog',\n",
    " 7: 'horse',\n",
    " 8: 'ship',\n",
    " 9: 'truck',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2a5b2",
   "metadata": {},
   "source": [
    "By deleting 2 of the 3 cells in the code above, you can select your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f122a77d",
   "metadata": {},
   "source": [
    "- How many classes does the dataset contain?\n",
    "- What are the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159169e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:33:28.215259Z",
     "start_time": "2021-10-05T06:33:28.208590Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = '''your code here'''\n",
    "nClasses = '''your code here'''\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b65890",
   "metadata": {},
   "source": [
    "- Draw the first and last image of the data set with its label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffa331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:35:04.962739Z",
     "start_time": "2021-10-05T06:35:04.482716Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image\n",
    "plt.subplot(121)\n",
    "'''your code here'''\n",
    "print(plt.title(\"(Label: \" + str(label_dict[target[0][0]]) + \")\"))\n",
    "\n",
    "# Display the last image of the dataset\n",
    "plt.subplot(122)\n",
    "'''your code here'''\n",
    "print(plt.title(\"(Label: \" + str(label_dict[target[1][0]]) + \")\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab4647",
   "metadata": {},
   "source": [
    "- Let's quickly check the maximum and minimum values of the images and <b>``normalize``</b> the pixels between 0 and 1 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810aec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:36:02.042687Z",
     "start_time": "2021-10-05T06:36:01.784419Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Before normalization:\", np.min(data),np.max(data))\n",
    "'''your code here'''\n",
    "print(\"After normalization: \", np.min(data),np.max(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10eec0",
   "metadata": {},
   "source": [
    "- Next, you will create a DataFrame that will hold the pixel values of the images along with their respective labels in a row-column format.\n",
    "\n",
    "- But before that, let's reshape the image dimensions to one (flatten the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad71bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:39:04.623156Z",
     "start_time": "2021-10-05T06:39:04.429922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "'''your code here'''\n",
    "\n",
    "# Build DataFrame\n",
    "feat_cols = ['pixel'+str(i) for i in range(data_flat.shape[1])]\n",
    "df = pd.DataFrame('''your code here''')\n",
    "df['label'] = target\n",
    "df['label'].replace(label_dict, inplace=True)\n",
    "print('Size of the dataframe: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cabad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:39:12.120114Z",
     "start_time": "2021-10-05T06:39:12.085696Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d79da",
   "metadata": {},
   "source": [
    "### Data visualization using PCA\n",
    "\n",
    "- Next, you will create the PCA method and pass the number of components as two and apply ``fit_transform`` on the training data (without the lavel), this can take few seconds since there are a lot of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43463d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:40:13.644331Z",
     "start_time": "2021-10-05T06:40:11.649325Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f7599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T05:36:15.913398Z",
     "start_time": "2021-10-05T05:36:15.905530Z"
    }
   },
   "source": [
    "- Then you will convert the principal components for each images from a numpy array to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e77b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:40:40.837926Z",
     "start_time": "2021-10-05T06:40:40.821119Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f8e4f9",
   "metadata": {},
   "source": [
    "- Let's quickly find out the amount of information or ``variance`` the principal components hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698cebe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:40:48.622396Z",
     "start_time": "2021-10-05T06:40:48.616747Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a168aeee",
   "metadata": {},
   "source": [
    "Well, it looks like a decent amount of information was retained by the principal components 1 and 2, given that the data was projected from a lot of dimensions to a mere two principal components.\n",
    "\n",
    "Its time to visualize the dataset in a two-dimensional space. Remember that there is some semantic class overlap in this dataset which means that a frog can have a slightly similar shape of a cat or a deer with a dog; especially when projected in a two-dimensional space. The differences between them might not be captured that well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb4ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:41:23.168700Z",
     "start_time": "2021-10-05T06:41:22.513626Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"principal component 1\", y=\"principal component 2\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=''' your PCA DataFrame here '''\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043f5d3",
   "metadata": {},
   "source": [
    "From the above figure, you can observe that some variation was captured by the principal components since there is some structure in the points when projected along the two principal component axis. The points belonging to the same class are close to each other, and the points or images that are very different semantically are further away from each other.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b5426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T16:27:55.707736Z",
     "start_time": "2021-10-04T16:27:55.282204Z"
    }
   },
   "source": [
    "### Data visualization using tSNE\n",
    "\n",
    "Now you will do the same exercise using the t-SNE algorithm. Scikit-learn has an implementation of t-SNE available, and you can check its documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). It provides a wide variety of tuning parameters for t-SNE, and the most notable ones are:\n",
    "- **n_components** (default: 2): Dimension of the embedded space.\n",
    "- **perplexity** (default: 30): The perplexity is related to the number of nearest neighbors that are used in other manifold learning algorithms. Consider selecting a value between 5 and 50.\n",
    "- **early_exaggeration** (default: 12.0): Controls how tight natural clusters in the original space are in the embedded space and how much space will be between them.\n",
    "- **learning_rate** (default: 200.0): The learning rate for t-SNE is usually in the range (10.0, 1000.0).\n",
    "- **nc** (default: 1000): Maximum number of iterations for the optimization. Should be at least 250.\n",
    "- **method** (default: â€˜barnes_hutâ€™): Barnes-Hut approximation runs in O(NlogN) time. method=â€™exactâ€™ will run on the slower, but exact, algorithm in O(N^2) time.\n",
    "\n",
    "Be careful: t-SNE takes much longer to run on the same data sample size than PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d2c09",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-05T06:44:28.205Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc90909",
   "metadata": {},
   "source": [
    "Then you will convert the projection for each images from a numpy array to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9921c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:42:54.725494Z",
     "start_time": "2021-10-05T06:42:54.725464Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd878d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T06:52:10.579694Z",
     "start_time": "2021-10-05T06:52:10.568100Z"
    }
   },
   "source": [
    "Its time to visualize the dataset in a two-dimensional space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6d3bf",
   "metadata": {},
   "source": [
    "- If the 2-D representation is not satisfactory i.e. if the classes are not well separated.It depends on the data set. Do a PCA projection keeping 80% of the explained variance, then apply a t-SNE projection.\n",
    "- **Attention:** depending on the dataset the calculation of the PCA for all features can be very long. Limit yourself to **50 components max.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f105c2",
   "metadata": {},
   "source": [
    "### Data visualization using LDA\n",
    "\n",
    "Do the same whith LDA projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87aa84c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T10:44:52.820660Z",
     "start_time": "2021-10-05T10:44:52.799853Z"
    }
   },
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404be336",
   "metadata": {},
   "source": [
    "- If the 2-D representation is not satisfactory i.e. if the classes are not well separated. It depends on the data set. Do a PCA 2-D projection in order to select the best components, then apply a LDA projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''your code here'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
