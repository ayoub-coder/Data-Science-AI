{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with Missing value, Outlier, Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Dataset\" data-toc-modified-id=\"Imports-and-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Dataset</a></span></li><li><span><a href=\"#Sampler,--transformer-and-estimator\" data-toc-modified-id=\"Sampler,--transformer-and-estimator-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sampler,  transformer and estimator</a></span></li><li><span><a href=\"#Lab-1:-Missing-value\" data-toc-modified-id=\"Lab-1:-Missing-value-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Lab 1: Missing value</a></span></li><li><span><a href=\"#Outlier-removal\" data-toc-modified-id=\"Outlier-removal-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Outlier removal</a></span></li><li><span><a href=\"#Unbalance-dataset\" data-toc-modified-id=\"Unbalance-dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Unbalance dataset</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:40.038388Z",
     "start_time": "2022-01-06T08:00:40.035775Z"
    }
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:41.037188Z",
     "start_time": "2022-01-06T08:00:40.442310Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import seaborn as sns                                     # For plotting data\n",
    "import pandas as pd                                       # For dataframes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                           # For plotting data\n",
    "%matplotlib inline\n",
    "\n",
    "# For splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For setting up pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn import FunctionSampler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# For Missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# For Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# For Unbalanced dataset\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# For classification\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "\n",
    "# For optimization\n",
    "from sklearn.model_selection import GridSearchCV      \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **original ForestCover/Covertype dataset** from UCI machine learning repository is a multiclass classification dataset. This dataset contains tree observations from four areas of the Roosevelt National Forest in Colorado. This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. \n",
    "\n",
    "In this notebook you are asked to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.\n",
    "\n",
    "This dataset has 54 attributes :\n",
    "* 10 quantitative variables,\n",
    "* 4 binary wilderness areas\n",
    "* and 40 binary soil type variables).\n",
    "Here, outlier detection dataset is created using only 10 quantitative attributes. Instances from class 2 are considered as normal points and instances from class 4 are anomalies. The anomalies ratio is 0.9%. Instances from the other classes are omitted.\n",
    "\n",
    "Dataset description available on [Kaggle](https://www.kaggle.com/uciml/forest-cover-type-dataset).\n",
    "* Elevation: Elevation in meters.\n",
    "* Aspect: Aspect in degrees azimuth.\n",
    "* Slope: Slope in degrees.\n",
    "* Horizontal_Distance_To_Hydrology: Horizontal distance in meters to nearest surface water features.\n",
    "* Vertical_Distance_To_Hydrology: Vertical distance in meters to nearest surface water features.\n",
    "* Horizontal_Distance_To_Roadways: Horizontal distance in meters to the nearest roadway.\n",
    "* Hillshade_9am: hillshade index at 9am, summer solstice. Value out of 255.\n",
    "* Hillshade_Noon: hillshade index at noon, summer solstice. Value out of 255.\n",
    "* Hillshade_3pm: shade index at 3pm, summer solstice. Value out of 255.\n",
    "* Horizontal_Distance_To_Fire_Point*: horizontal distance in meters to nearest wildfire ignition points.\n",
    "* Wilderness_Area#: wilderness area designation.\n",
    "* Soil_Type#: soil type designation.\n",
    "\n",
    "Wilderness_Area feature is one-hot encoded to 4 binary columns (0 = absence or 1 = presence), each of these corresponds to a wilderness area designation. Areas are mapped to value in the following way:\n",
    "1. Rawah Wilderness Area\n",
    "1. Neota Wilderness Area\n",
    "1. Comanche Peak Wilderness Area\n",
    "1. Cache la Poudre Wilderness Area\n",
    "\n",
    "The same goes for Soil_Type feature which is encoded as 40 one-hot encoded binary columns (0 = absence or 1 = presence) and each of these represents soil type designation. All the possible options are:\n",
    "1. Cathedral family - Rock outcrop complex, extremely stony\n",
    "1. Vanet - Ratake families complex, very stony\n",
    "1. Haploborolis - Rock outcrop complex, rubbly\n",
    "1. Ratake family - Rock outcrop complex, rubbly\n",
    "1. Vanet family - Rock outcrop complex complex, rubbly\n",
    "1. Vanet - Wetmore families - Rock outcrop complex, stony\n",
    "1. Gothic family\n",
    "1. Supervisor - Limber families complex\n",
    "1. Troutville family, very stony\n",
    "1. Bullwark - Catamount families - Rock outcrop complex, rubbly\n",
    "1. Bullwark - Catamount families - Rock land complex, rubbly.\n",
    "1. Legault family - Rock land complex, stony\n",
    "1. Catamount family - Rock land - Bullwark family complex, rubbly\n",
    "1. Pachic Argiborolis - Aquolis complex\n",
    "1. Â¨unspecified in the USFS Soil and ELU Survey\n",
    "1. Cryaquolis - Cryoborolis complex\n",
    "1. Gateview family - Cryaquolis complex\n",
    "1. Rogert family, very stony\n",
    "1. Typic Cryaquolis - Borohemists complex\n",
    "1. Typic Cryaquepts - Typic Cryaquolls complex\n",
    "1. Typic Cryaquolls - Leighcan family, till substratum complex\n",
    "1. Leighcan family, till substratum, extremely bouldery\n",
    "1. Leighcan family, till substratum - Typic Cryaquolls complex\n",
    "1. Leighcan family, extremely stony\n",
    "1. Leighcan family, warm, extremely stony\n",
    "1. Granile - Catamount families complex, very stony\n",
    "1. Leighcan family, warm - Rock outcrop complex, extremely stony\n",
    "1. Leighcan family - Rock outcrop complex, extremely stony\n",
    "1. Como - Legault families complex, extremely stony\n",
    "1. Como family - Rock land - Legault family complex, extremely stony\n",
    "1. Leighcan - Catamount families complex, extremely stony\n",
    "1. Catamount family - Rock outcrop - Leighcan family complex, extremely stony\n",
    "1. Leighcan - Catamount families - Rock outcrop complex, extremely stony\n",
    "1. Cryorthents - Rock land complex, extremely stony\n",
    "1. Cryumbrepts - Rock outcrop - Cryaquepts complex\n",
    "1. Bross family - Rock land - Cryumbrepts complex, extremely stony\n",
    "1. Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony\n",
    "1. Leighcan - Moran families - Cryaquolls complex, extremely stony\n",
    "1. Moran family - Cryorthents - Leighcan family complex, extremely stony\n",
    "1. Moran family - Cryorthents - Rock land complex, extremely stony\n",
    "\n",
    "Cover_Type: forest cover type designation, its possible values are between 1 and 7, mapped in the following way:\n",
    "1. Spruce/Fir\n",
    "1. Lodgepole Pine\n",
    "1. Ponderosa Pine\n",
    "1. Cottonwood/Willow\n",
    "1. Aspen\n",
    "1. Douglas-fir\n",
    "1. Krummholz\n",
    "\n",
    "<font color=blue>\n",
    "We will use a very small part of this dataset with only classes 1 and 7.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:00:58.376165Z",
     "start_time": "2022-01-06T08:00:58.373811Z"
    }
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = \"https://www.i3s.unice.fr/~riveill/dataset/covtype/\"\n",
    "filename = \"covtype.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:14.251808Z",
     "start_time": "2022-01-06T08:01:13.894125Z"
    }
   },
   "outputs": [],
   "source": [
    "# load train and test\n",
    "train = pd.read_csv(url+\"train.csv\", delimiter=',')\n",
    "test = pd.read_csv(url+\"test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:14.858602Z",
     "start_time": "2022-01-06T08:01:14.855174Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = list(train.columns)\n",
    "target = 'Cover_Type'\n",
    "columns.remove(target)\n",
    "cat_columns=[c for c in columns if 'Soil_Type' in c or 'Wilderness_Area' in c] # already one hot encode\n",
    "num_columns=[c for c in columns if c not in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:15.395465Z",
     "start_time": "2022-01-06T08:01:15.381422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 54), (10000, 54))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(train[target]).reshape(-1,1)\n",
    "X_train = train[columns]\n",
    "\n",
    "y_test = np.array(test[target]).reshape(-1,1)\n",
    "X_test = test[columns]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:15.793149Z",
     "start_time": "2022-01-06T08:01:15.788504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 9083, 7: 917}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "distribution = pd.Series(y_train.flatten()).value_counts().to_dict()\n",
    "distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler,  transformer and estimator\n",
    "\n",
    "There are three types of objects in imblearn/scikit-learn design:\n",
    "\n",
    "**Transformer** transform observation (modify only X_train) and implements:\n",
    "* fit: used for calculating the initial parameters on the training data and later saves them as internal objects state.\n",
    "* transform: Use the initial above calculated values and return modified training data as output. Do not modify the length of the dataset.\n",
    "\n",
    "**Predictor** is a \"model\" and implements:\n",
    "* fit: calculates the parameters or weights on the training data and saves them as an internal object state.\n",
    "* predict: Use the above-calculated weights on the test data to make the predictions.\n",
    "\n",
    "**Sampler** is a new element, from imblearn library. A sampler modifies the number of observations in the train set (modify X_train and y_train) and implements:\n",
    "* fit_resample\n",
    "\n",
    "The following cells build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:16.440347Z",
     "start_time": "2022-01-06T08:01:16.437511Z"
    }
   },
   "outputs": [],
   "source": [
    "# A sampler\n",
    "class mySampler(BaseEstimator):\n",
    "    def fit_resample(self, X, y):\n",
    "        data = np.concatenate((X, y), axis=1)\n",
    "        # remove rows with NaN\n",
    "        data = data[~np.isnan(data).any(axis=1), :]\n",
    "        return data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to build sampler from a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:16.900610Z",
     "start_time": "2022-01-06T08:01:16.897194Z"
    }
   },
   "outputs": [],
   "source": [
    "def mySamplerFunction(X, y, conta=0.1):\n",
    "    iforest = IsolationForest(n_estimators=300, max_samples='auto', contamination=conta)\n",
    "    outliers = iforest.fit_predict(X, y)\n",
    "\n",
    "    X_filtered = X[outliers == 1]\n",
    "    y_filtered = y[outliers == 1]\n",
    "\n",
    "    return X_filtered, y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:17.384561Z",
     "start_time": "2022-01-06T08:01:17.381000Z"
    }
   },
   "outputs": [],
   "source": [
    "# A transformer\n",
    "class myTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy=\"most_frequent\"):\n",
    "        self.strategy = strategy\n",
    "        self.sample = SimpleImputer(strategy=self.strategy)\n",
    "    def fit(self, X, y=None):\n",
    "        return self.sample.fit(X, y)\n",
    "    def transform(self, X):\n",
    "        return self.sample.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like sampler, it's also possible to build transformer from a function see `sklearn.preprocessing.FunctionTransform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:17.944197Z",
     "start_time": "2022-01-06T08:01:17.941082Z"
    }
   },
   "outputs": [],
   "source": [
    "# A predictor\n",
    "class myPredictor(BaseEstimator):\n",
    "    def __init__(self, penalty=\"l2\"):\n",
    "        self.penalty = penalty\n",
    "        self.sample = LogisticRegression(solver=\"lbfgs\", penalty=self.penalty, max_iter=10000)\n",
    "    def fit(self, X, y):\n",
    "        return self.sample.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.sample.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:18.188956Z",
     "start_time": "2022-01-06T08:01:18.180933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_data', None),\n",
       "                ('outlier',\n",
       "                 FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                ('clf', None)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different version of the 2 steps pipeline\n",
    "# step 1 : remove or imput missing data\n",
    "# step 2 : remove outlier\n",
    "# step 3 : predictor\n",
    "pipeline = Pipeline([('missing_data', None),\n",
    "                     ('outlier', FunctionSampler(func=mySamplerFunction)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "parameters = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent'],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              ]\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:18.425350Z",
     "start_time": "2022-01-06T08:01:18.415090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch with pipeline\n",
    "grid = GridSearchCV(pipeline, parameters, cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "Remember: samplers are only called to perform the \"fit\" and not to perform the predict. If the data set contains missing values (NaN) in the validation part, a warning may be raised.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:21.375699Z",
     "start_time": "2022-01-06T08:01:18.872513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-24-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 425, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 407, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-24-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 425, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 407, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   1.4s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   1.3s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [ nan 0.64]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor(penalty='none')],\n",
       "                          'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to find the best model\n",
    "grid.fit(X_train[:50], y_train[:50]) # Some data for testing the process... but use all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T08:01:21.389682Z",
     "start_time": "2022-01-06T08:01:21.377854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.66 using {'clf': myPredictor(penalty='none'), 'clf__penalty': 'none', 'missing_data': myTransformer(), 'missing_data__strategy': 'most_frequent'}\n",
      "Test set score: 0.816\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the whole dataset\n",
    "y_pred = grid.predict(X_train[:500])\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid.best_score_, \n",
    "    grid.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid.score(X_train[:500], y_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Missing value\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to handle missing data.\n",
    "* Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. with removal of missing data\n",
    "1. with of the following imputation methods\n",
    "    * With SimpleImputer\n",
    "    * With IterativeImputer\n",
    "    * With KNNimputer\n",
    "\n",
    "Build a 2 step pipeline and use a gridsearch to find the right hyperpameters.\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_data', None),\n",
       "                ('outlier',\n",
       "                 FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                ('clf', None)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different version of the 2 steps pipeline\n",
    "# step 1 : remove or imput missing data\n",
    "# step 2 : remove outlier\n",
    "# step 3 : predictor\n",
    "pipeline_1 = Pipeline([('missing_data', None),\n",
    "                     ('outlier', FunctionSampler(func=mySamplerFunction)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "parameters = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent','mean','median'],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              ]\n",
    "\n",
    "pipeline_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent', 'mean',\n",
       "                                                     'median']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch with pipeline\n",
    "grid_1 = GridSearchCV(pipeline_1, parameters, cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n",
    "grid_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-24-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 425, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 407, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-24-2937ca012408>\", line 9, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 425, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 407, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   1.2s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   1.1s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   1.4s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=mean; total time=   1.1s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=mean; total time=   1.1s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=median; total time=   1.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=median; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [ nan 0.64 0.66 0.64]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor(penalty='none')],\n",
       "                          'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer(strategy='mean')],\n",
       "                          'missing_data__strategy': ['most_frequent', 'mean',\n",
       "                                                     'median']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to find the best model\n",
    "grid_1.fit(X_train[:50], y_train[:50]) # Some data for testing the process... but use all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.66 using {'clf': myPredictor(penalty='none'), 'clf__penalty': 'none', 'missing_data': myTransformer(strategy='mean'), 'missing_data__strategy': 'mean'}\n",
      "Test set score: 0.772\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the whole dataset\n",
    "y_pred = grid_1.predict(X_train[:500])\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid_1.best_score_, \n",
    "    grid_1.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid_1.score(X_train[:500], y_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 1:** <br> \n",
    "I compute the Logisitics regression classification with transformer strategy that takes for an input **'most_frequent','mean', and 'median'** <br>\n",
    "the parameter choosen with GridSearchCV is **Mean**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A predictor\n",
    "class myPredictor_Tree(BaseEstimator):\n",
    "    def __init__(self, max_depth=2,min_samples_leaf=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf=min_samples_leaf\n",
    "        self.sample = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "    def fit(self, X, y):\n",
    "        return self.sample.fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.sample.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_data', None),\n",
       "                ('outlier',\n",
       "                 FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                ('clf', None)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different version of the 2 steps pipeline\n",
    "# step 1 : remove or imput missing data\n",
    "# step 2 : remove outlier\n",
    "# step 3 : predictor\n",
    "pipeline_2 = Pipeline([('missing_data', None),\n",
    "                     ('outlier', FunctionSampler(func=mySamplerFunction)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "parameters = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor_Tree()],\n",
    "               'clf__max_depth':np.arange(2, 5, 1),\n",
    "               'clf__min_samples_leaf':np.arange(2, 5, 1),\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent'],\n",
    "               'clf': [myPredictor_Tree()],\n",
    "               'clf__max_depth':np.arange(2, 5, 1),\n",
    "               'clf__min_samples_leaf':np.arange(2, 5, 1),\n",
    "              },\n",
    "              ]\n",
    "\n",
    "pipeline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor_Tree()],\n",
       "                          'clf__max_depth': array([2, 3, 4]),\n",
       "                          'clf__min_samples_leaf': array([2, 3, 4]),\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor_Tree()],\n",
       "                          'clf__max_depth': array([2, 3, 4]),\n",
       "                          'clf__min_samples_leaf': array([2, 3, 4]),\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch with pipeline\n",
    "grid_2 = GridSearchCV(pipeline_2, parameters, cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n",
    "grid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=2, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=3, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 470, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "  File \"<ipython-input-43-e6f64362601b>\", line 10, in predict\n",
      "    return self.sample.predict(X)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 467, in predict\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 433, in _validate_X_predict\n",
      "    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 114, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=4, missing_data=mySampler(); total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=2, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=3, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=2, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.4s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=3, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.6s\n",
      "[CV] END clf=myPredictor_Tree(), clf__max_depth=4, clf__min_samples_leaf=4, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [ nan  nan  nan  nan  nan  nan  nan  nan  nan 0.86 0.88 0.88 0.86 0.9\n",
      " 0.9  0.88 0.88 0.88]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869B58550>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor_Tree()],\n",
       "                          'clf__max_depth': array([2, 3, 4]),\n",
       "                          'clf__min_samples_leaf': array([2, 3, 4]),\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor_Tree(max_depth=3,\n",
       "                                                   min_samples_leaf=3)],\n",
       "                          'clf__max_depth': array([2, 3, 4]),\n",
       "                          'clf__min_samples_leaf': array([2, 3, 4]),\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to find the best model\n",
    "grid_2.fit(X_train[:50], y_train[:50]) # Some data for testing the process... but use all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.90 using {'clf': myPredictor_Tree(max_depth=3, min_samples_leaf=3), 'clf__max_depth': 3, 'clf__min_samples_leaf': 3, 'missing_data': myTransformer(), 'missing_data__strategy': 'most_frequent'}\n",
      "Test set score: 0.914\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the whole dataset\n",
    "y_pred2 = grid_2.predict(X_train[:500])\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid_2.best_score_, \n",
    "    grid_2.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid_2.score(X_train[:500], y_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> **Conclusion** <br>\n",
    "In this second model, I applied Decision Tree and tuned different parameters :\"max_depth\" and \"min_samples_leaf\". <br>\n",
    "The best model is decisionTree with the parameters : (max_depth=3, min_samples_leaf=3). <br>\n",
    "The accuracy of the testing data has improved with \"91%\" accuraccy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal\n",
    "\n",
    "Removing the outliers modifies the data set, so it is a sampler.\n",
    "\n",
    "<font color='blue'> \n",
    "IsolationForest or other sklearn detector are not a sampler. You have to read the </font>[imblearn documentation](https://imbalanced-learn.org/dev/references/generated/imblearn.FunctionSampler.html)\n",
    "    \n",
    "A small example with parameters:\n",
    "<pre>\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def func(X, y, sampling_strategy, random_state):\n",
    "  return RandomUnderSampler(\n",
    "      sampling_strategy=sampling_strategy,\n",
    "      random_state=random_state).fit_resample(X, y)\n",
    "      \n",
    "sampler = FunctionSampler(func=func,\n",
    "                          kw_args={'sampling_strategy': 'auto',\n",
    "                                   'random_state': 0})\n",
    "X_res, y_res = sampler.fit_resample(X, y)\n",
    "print(f'Resampled dataset shape {sorted(Counter(y_res).items())}')\n",
    "</pre>\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to handle outliers.\n",
    "* Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. Without taking any precautions\n",
    "1. By eliminating outliers with one of the following approaches:\n",
    "    * With Isolation Forest (IF)\n",
    "    * With Local Outlier Factor (LOF)\n",
    "    * With Minimum Covariance Determinant (MCD)\n",
    "\n",
    "Build a 3 step pipeline and use a gridsearch to find the right hyperpameters.\n",
    "The first step, is your best previous \"missing data method\".\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySamplerFunction_lfactor(X, y, conta=0.1):\n",
    "    lfactor = LocalOutlierFactor(n_neighbors=30, contamination=conta)\n",
    "    outliers_1 = lfactor.fit_predict(X, y)\n",
    "\n",
    "    X_filtered_1 = X[outliers_1 == 1]\n",
    "    y_filtered_1 = y[outliers_1 == 1]\n",
    "\n",
    "    return X_filtered_1, y_filtered_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('missing_data', None),\n",
       "                ('outlier',\n",
       "                 FunctionSampler(func=<function mySamplerFunction_lfactor at 0x0000018869C45280>)),\n",
       "                ('clf', None)])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different version of the 2 steps pipeline\n",
    "# step 1 : remove or imput missing data\n",
    "# step 2 : remove outlier\n",
    "# step 3 : predictor\n",
    "pipeline_3 = Pipeline([('missing_data', None),\n",
    "                     ('outlier', FunctionSampler(func=mySamplerFunction_lfactor)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "parameters = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent'],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              ]\n",
    "\n",
    "pipeline_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction_lfactor at 0x0000018869C45280>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch with pipeline\n",
    "grid_3 = GridSearchCV(pipeline_3, parameters, cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n",
    "grid_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_lof.py:284: UserWarning: n_neighbors (30) is greater than the total number of samples (25). n_neighbors will be set to (n_samples - 1) for estimation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_lof.py:284: UserWarning: n_neighbors (30) is greater than the total number of samples (25). n_neighbors will be set to (n_samples - 1) for estimation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 4.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 262, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 220, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 388, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"<ipython-input-17-041db026a889>\", line 4, in fit_resample\n",
      "    data = np.concatenate((X, y), axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
      "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [ nan 0.68]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction_lfactor at 0x0000018869C45280>)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor(penalty='none')],\n",
       "                          'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to find the best model\n",
    "grid_3.fit(X_train[:50], y_train[:50]) # Some data for testing the process... but use all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.68 using {'clf': myPredictor(penalty='none'), 'clf__penalty': 'none', 'missing_data': myTransformer(), 'missing_data__strategy': 'most_frequent'}\n",
      "Test set score: 0.884\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the whole dataset\n",
    "y_pred = grid_3.predict(X_train[:500])\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid_3.best_score_, \n",
    "    grid_3.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid_3.score(X_train[:500], y_train[:500])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalance dataset\n",
    "\n",
    "$$[TO DO - Students]$$\n",
    "\n",
    "Test some algorithms to work with unbalanced dataset.\n",
    "Choose the classifier that you think is preferable for this job.\n",
    "\n",
    "1. Without taking any precautions\n",
    "1. With modification of the dataset by Over sampling or Under sampling or SMOTE\n",
    "1. Without modification of the dataset by weight\n",
    "\n",
    "Build a 4 step pipeline and use a gridsearch to find the right hyperpameters and use a gridsearch to find the right hyperpameters. The first and second step, is your best previous methods.\n",
    "\n",
    "Submit your work in the form of an executable and commented notebook at lms.univ-cotedazur.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Without taking any precautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res,y_res = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape [(1, 9083), (7, 9083)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Resampled dataset shape {sorted(Counter(y_res).items())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this pipline bellow, SMOTE() sampling has been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "        ('missing_data', None),\n",
    "                     ('outlier',FunctionSampler(func=mySamplerFunction)), ('sampling', SMOTE(k_neighbors=20)),\n",
    "                     ('clf', None)])\n",
    "\n",
    "\n",
    "params = [{'missing_data': [mySampler()],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              {'missing_data': [myTransformer()],\n",
    "               'missing_data__strategy': ['most_frequent'],\n",
    "               'clf': [myPredictor()],\n",
    "               'clf__penalty': ['none'],\n",
    "              },\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid4 = GridSearchCV(model, params,cv=2,\n",
    "                    scoring=\"f1_micro\", refit=True,\n",
    "                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=mySampler(); total time=   0.0s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=  12.6s\n",
      "[CV] END clf=myPredictor(), clf__penalty=none, missing_data=myTransformer(), missing_data__strategy=most_frequent; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 4.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 262, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 220, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 388, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"<ipython-input-17-041db026a889>\", line 4, in fit_resample\n",
      "    data = np.concatenate((X, y), axis=1)\n",
      "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
      "ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Polytech\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [   nan 0.8681]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('missing_data', None),\n",
       "                                       ('outlier',\n",
       "                                        FunctionSampler(func=<function mySamplerFunction at 0x0000018869C450D0>)),\n",
       "                                       ('sampling', SMOTE(k_neighbors=20)),\n",
       "                                       ('clf', None)]),\n",
       "             param_grid=[{'clf': [myPredictor()], 'clf__penalty': ['none'],\n",
       "                          'missing_data': [mySampler()]},\n",
       "                         {'clf': [myPredictor(penalty='none')],\n",
       "                          'clf__penalty': ['none'],\n",
       "                          'missing_data': [myTransformer()],\n",
       "                          'missing_data__strategy': ['most_frequent']}],\n",
       "             scoring='f1_micro', verbose=2)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.87 using {'clf': myPredictor(penalty='none'), 'clf__penalty': 'none', 'missing_data': myTransformer(), 'missing_data__strategy': 'most_frequent'}\n",
      "Test set score: 0.8653\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = grid4.predict(X_train)\n",
    "print(\"Best: {:.2f} using {}\".format(\n",
    "    grid4.best_score_, \n",
    "    grid4.best_params_\n",
    "))\n",
    "print('Test set score: ' + str(grid4.score(X_train, y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
