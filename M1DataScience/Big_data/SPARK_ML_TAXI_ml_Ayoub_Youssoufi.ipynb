{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///tmp\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:06 hdfs:///user\r\n",
      "drwx-wx-wx   - hive hadoop          0 2022-01-04 02:04 hdfs:///var\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls hdfs:///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cp file:///yellow_tripdata_2020-01.csv /user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 items\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/dataproc\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/hbase\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/hdfs\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/hive\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/mapred\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/pig\r\n",
      "drwxr-xr-x   - root hadoop          0 2022-01-04 02:06 hdfs:///user/root\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/spark\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/yarn\r\n",
      "-rw-r--r--   2 root hadoop  593610736 2022-01-04 02:07 hdfs:///user/yellow_tripdata_2020-01.csv\r\n",
      "drwxrwxrwt   - hdfs hadoop          0 2022-01-04 02:04 hdfs:///user/zookeeper\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls hdfs:///user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOALS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Provide basic data exploration results on the dataset <br>\n",
    "\n",
    "2. predicting the reception of Tips for a taxi New York City rider given the features bellow : <br>\n",
    "\"trip_distance\",\"fare_amount\",\"payment_type\",\"tip_amount\",\"tolls_amount\"...etc <br>\n",
    "The amount of tips received is numerical. Therefore, we will categorize this feature in order to apply **logistic regression** classifier.<br>  the categories are following : \n",
    "*  The driver didn't receive any tips is :**\" NNtips\"**\n",
    "*  The driver receive a tips is **\"Tip\"**\n",
    "*  The driver receive generous Tip **\"GTips\"**\n",
    "3. To run this file, first you need to import the dataset with the command \"wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6405008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.csv(\"hdfs:///user/yellow_tripdata_2020-01.csv\",header='true',inferSchema=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"hdfs:///user/yellow_tripdata_2020-01.csv\",header=True, inferSchema=True).sample(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"VendorID\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"RatecodeID\",\"congestion_surcharge\",\"DOLocationID\",\"PULocationID\",\"store_and_fwd_flag\",\"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+\n",
      "|passenger_count|trip_distance|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|\n",
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+\n",
      "|              2|          2.4|           1|       11.0|  3.0|    0.5|       1.0|         0.0|                  0.3|\n",
      "|              2|         0.91|           1|        7.5|  0.5|    0.5|      1.13|         0.0|                  0.3|\n",
      "|              1|          3.8|           2|       17.5|  3.0|    0.5|       0.0|         0.0|                  0.3|\n",
      "|              1|          3.4|           1|       12.0|  0.5|    0.5|      2.37|         0.0|                  0.3|\n",
      "|              1|         3.94|           1|       14.0|  0.5|    0.5|      3.56|         0.0|                  0.3|\n",
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, when\n",
    "tipsCol = when(\n",
    "    col(\"tip_amount\")>2.2,\"GTips\").when(col(\"tip_amount\")==0, \"NNTips\").otherwise(\"Tips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn(\"tipsCol\", tipsCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+-------+\n",
      "|passenger_count|trip_distance|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|tipsCol|\n",
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+-------+\n",
      "|              2|          2.4|           1|       11.0|  3.0|    0.5|       1.0|         0.0|                  0.3|   Tips|\n",
      "|              2|         0.91|           1|        7.5|  0.5|    0.5|      1.13|         0.0|                  0.3|   Tips|\n",
      "|              1|          3.8|           2|       17.5|  3.0|    0.5|       0.0|         0.0|                  0.3| NNTips|\n",
      "|              1|          3.4|           1|       12.0|  0.5|    0.5|      2.37|         0.0|                  0.3|  GTips|\n",
      "|              1|         3.94|           1|       14.0|  0.5|    0.5|      3.56|         0.0|                  0.3|  GTips|\n",
      "+---------------+-------------+------------+-----------+-----+-------+----------+------------+---------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(tipsCol='NNTips'), Row(tipsCol='GTips'), Row(tipsCol='Tips')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('tipsCol').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "df= StringIndexer(inputCol=\"tipsCol\",outputCol=\"label\").fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0), Row(label=1.0), Row(label=2.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('label').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'passenger_count','trip_distance','payment_type','fare_amount','extra','mta_tax','tolls_amount','improvement_surcharge'\n",
    "], outputCol='features',handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembled = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|tip_amount|\n",
      "+--------------------+----------+\n",
      "|[2.0,2.4,1.0,11.0...|       1.0|\n",
      "|[2.0,0.91,1.0,7.5...|      1.13|\n",
      "|[1.0,3.8,2.0,17.5...|       0.0|\n",
      "|[1.0,3.4,1.0,12.0...|      2.37|\n",
      "|[1.0,3.94,1.0,14....|      3.56|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembled.select('features', 'tip_amount').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- tipsCol: string (nullable = false)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_assembled.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "df_assembled_train, df_assembled_test = df_assembled.randomSplit([0.8,0.2], seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[495, 108]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df_assembled_train.count(), df_assembled_test.count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:===================>                                      (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208955223880597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_ratio = df_assembled_train.count() / df_assembled.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import the Decision Tree Classifier class\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(df_assembled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------------------------------------------------------+\n",
      "|label|prediction|probability                                                 |\n",
      "+-----+----------+------------------------------------------------------------+\n",
      "|2.0  |2.0       |[0.0,0.0,1.0]                                               |\n",
      "|1.0  |1.0       |[0.05128205128205128,0.9145299145299145,0.03418803418803419]|\n",
      "|2.0  |2.0       |[0.0,0.0,1.0]                                               |\n",
      "|0.0  |1.0       |[0.05128205128205128,0.9145299145299145,0.03418803418803419]|\n",
      "|1.0  |1.0       |[0.05128205128205128,0.9145299145299145,0.03418803418803419]|\n",
      "+-----+----------+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = tree_model.transform(df_assembled_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:===================>                                      (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  2.0|       0.0|    1|\n",
      "|  1.0|       1.0|   23|\n",
      "|  0.0|       1.0|    6|\n",
      "|  2.0|       2.0|   24|\n",
      "|  1.0|       0.0|   14|\n",
      "|  2.0|       1.0|    2|\n",
      "|  0.0|       0.0|   38|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins> Metrics for our model:<ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y_true = prediction.select(['label']).collect()\n",
    "y_pred = prediction.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.86      0.78        44\n",
      "         1.0       0.74      0.62      0.68        37\n",
      "         2.0       1.00      0.89      0.94        27\n",
      "\n",
      "    accuracy                           0.79       108\n",
      "   macro avg       0.82      0.79      0.80       108\n",
      "weighted avg       0.80      0.79      0.79       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins> **Summary** </ins> <br>\n",
    "From the classification report above, the precision of the labeled data (0,1,2) is high. <br>\n",
    "This means that most of the labeled data from a class wasn't predicted as another type of class. <br>\n",
    "For example, the labeled data 0 has 74 % precision. This means that not many labeled data \"0\" was predicted as \"1\" or \"2\" <br>\n",
    "<br>\n",
    "The recall shows also that most of our labels \"0\",\"1\",and \"2\" are correctly predicted with our model decision tree. \n",
    "<br>\n",
    "The average weighted accuracy is also high with 84%. Our model is more likely to classify our classes correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins> Confusion Matrix <ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  6  0]\n",
      " [14 23  0]\n",
      " [ 1  2 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:===================>                                      (2 + 4) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted precision 0.80 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "print(\"weighted precision %.2f \" % weighted_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins> **Conclusion** </ins> <br>\n",
    "Given the results above, I have been able to build a classifier that will predict where the trip is more likely to result <br>\n",
    "in either \"No tip\", \"Tip\"or \"Generous tip\". <br>\n",
    "This classifier can help in fraud detection. For instance, a taxi driver has received tips. however, he desclaims <br>\n",
    "receiving any tips in order to avoid tax consequences.<br>\n",
    "Our model can detect the fraud with 80% accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>In this section, I will build **LogisticRegression Model** using  **Pipeline** method <ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_rg=spark.read.csv(\"hdfs:///user/yellow_tripdata_2020-01.csv\",header=True, inferSchema=True).sample(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg=df_rg.drop(\"VendorID\",\"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\"RatecodeID\",\"congestion_surcharge\",\"DOLocationID\",\"PULocationID\",\"store_and_fwd_flag\",\"total_amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, when\n",
    "tipsCol = when(\n",
    "    col(\"tip_amount\")>2.2,\"GTips\").when(col(\"tip_amount\")==0, \"NNTips\").otherwise(\"Tips\")\n",
    "df_rg=df_rg.withColumn(\"tipsCol\", tipsCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_rg= StringIndexer(inputCol=\"tipsCol\",outputCol=\"label_rg\")\n",
    "assembler_rg = VectorAssembler(inputCols=[\n",
    "    'passenger_count','trip_distance','payment_type','fare_amount','extra','mta_tax','tolls_amount','improvement_surcharge'\n",
    "], outputCol='features',handleInvalid=\"skip\")\n",
    "rg = LogisticRegression(labelCol=\"label_rg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer_rg, assembler_rg, rg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- tipsCol: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "df_rg_train, df_rg_test = df_rg.randomSplit([0.8,0.2], seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline.fit(df_rg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.transform(df_rg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y_true1 = predictions.select(['label_rg']).collect()\n",
    "y_pred1 = predictions.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.68      0.70        50\n",
      "         1.0       0.61      0.71      0.66        35\n",
      "         2.0       1.00      0.91      0.96        35\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.78      0.77      0.77       120\n",
      "weighted avg       0.77      0.76      0.76       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34 16  0]\n",
      " [10 25  0]\n",
      " [ 3  0 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, the accuracy of our model is 77% less than the decision tree classifier <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
